{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Recommendation\n",
    "### University of Virginia\n",
    "### DS 7200: Distributed Computing\n",
    "### Last Updated: August 20, 2023\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "\n",
    "In this assignment, you will prepare data and build an ALS recommendation algorithm based on user listening data from Autoscrobbler.\n",
    "\n",
    "The data consists of: \n",
    "- user data (listeners)\n",
    "- item data (songs)\n",
    "- interaction data (user listens, which is implicit feedback).  \n",
    "\n",
    "The code is outlined below. Make the requested modifications, run the code, and copy all answers to the **ANSWER SECTION** at the bottom of the notebook. Note the *None* variable is a placeholder for code.\n",
    "\n",
    "**NOTE**: For a given userID, some/many recommendation might come back as $None$.  \n",
    "This comes from artists not used in the training data.  \n",
    "These should be filtered out using a list comprehension as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`print([x for x in recommendationsForUser if x is not None])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TOTAL POINTS: 10**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.mllib import recommendation\n",
    "from pyspark.mllib.recommendation import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set configurations\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"autoscrobbler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/17 21:22:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# set context\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pathing and params\n",
    "user_artist_data_file = '/standard/ds7200-apt4c/large_datasets/user_artist_data.txt'\n",
    "artist_data_file = 'artist_data.txt'\n",
    "artist_alias_data_file  = 'artist_alias.txt'\n",
    "\n",
    "numPartitions = 2\n",
    "topk = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/standard/ds7200-apt4c/large_datasets/user_artist_data.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read user_artist_data_file into RDD (417MB file, 24MM records of users’ plays of artists, along with count)\n",
    "# specifically, each row holds: userID, artistID, count\n",
    "rawDataRDD = sc.textFile(user_artist_data_file, numPartitions)\n",
    "rawDataRDD.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/17 21:22:18 WARN BlockManager: Task 0 already completed, not releasing lock for rdd_1_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1000002 1 55', '1000002 1000006 33']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect some records\n",
    "rawDataRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_data.txt MapPartitionsRDD[4] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read artist_data_file using *textFile*\n",
    "rawArtistRDD = sc.textFile(artist_data_file, numPartitions)\n",
    "rawArtistRDD.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/17 21:22:18 WARN BlockManager: Task 1 already completed, not releasing lock for rdd_4_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1134999\\t06Crazy Life', '6821360\\tPang Nakarin']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect some records\n",
    "rawArtistRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_alias.txt MapPartitionsRDD[7] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read artist_alias_data_file using *textFile*\n",
    "rawAliasRDD = sc.textFile(artist_alias_data_file, numPartitions)\n",
    "rawAliasRDD.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/17 21:22:18 WARN BlockManager: Task 2 already completed, not releasing lock for rdd_7_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1092764\\t1000311', '1095122\\t1000557']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect some records\n",
    "rawAliasRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/17 21:22:18 WARN BlockManager: Task 3 already completed, not releasing lock for rdd_1_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1000002 1 55',\n",
       " '1000002 1000006 33',\n",
       " '1000002 1000007 8',\n",
       " '1000002 1000009 144',\n",
       " '1000002 1000010 314',\n",
       " '1000002 1000013 8',\n",
       " '1000002 1000014 42',\n",
       " '1000002 1000017 69',\n",
       " '1000002 1000024 329',\n",
       " '1000002 1000025 1']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) (1 PT) Print the first 10 records from rawDataRDD\n",
    "rawDataRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) (1 PT) Apply parseArtistIdNamePair to rawArtistRDD, and print the first 10 records, showing only artist names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parseArtistIdNamePair(singlePair):\n",
    "   splitPair = singlePair.rsplit('\\t')\n",
    "   # we should have two items in the list - id and name of the artist.\n",
    "   if len(splitPair) != 2:\n",
    "       #print singlePair\n",
    "       return []\n",
    "   else:\n",
    "       try:\n",
    "           return [(int(splitPair[0]), splitPair[1])]\n",
    "       except:\n",
    "           return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06Crazy Life',\n",
       " 'Pang Nakarin',\n",
       " 'Terfel, Bartoli- Mozart: Don',\n",
       " 'The Flaming Sidebur',\n",
       " 'Bodenstandig 3000',\n",
       " 'Jota Quest e Ivete Sangalo',\n",
       " 'Toto_XX (1977',\n",
       " 'U.S Bombs -',\n",
       " 'artist formaly know as Mat',\n",
       " 'Kassierer - Musik für beide Ohren']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artistByID = dict(rawArtistRDD.flatMap(lambda x: parseArtistIdNamePair(x)).collect())\n",
    "artist_vals = artistByID.values()\n",
    "list(artist_vals)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parseArtistAlias(alias):\n",
    "    splitPair = alias.rsplit('\\t')\n",
    "    # we should have two ids in the list.\n",
    "    if len(splitPair) != 2:\n",
    "        #print singlePair\n",
    "        return []\n",
    "    else:\n",
    "        try:\n",
    "            return [(int(splitPair[0]), int(splitPair[1]))]\n",
    "        except:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "artistAlias = rawAliasRDD.flatMap(lambda x: parseArtistAlias(x)).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# turn the artistAlias into a broadcast variable.\n",
    "# This will distribute it to worker nodes efficiently, so we save bandwidth.\n",
    "artistAliasBroadcast = sc.broadcast( artistAlias )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007797"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artistAliasBroadcast.value.get(2097174)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:====================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24296858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print the number of records from the largest RDD, rawDataRDD\n",
    "print( rawDataRDD.count() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[13] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 10% of rawDataRDD (to reduce runtime) using seed 314. Call it sample.\n",
    "seed = 314\n",
    "weights = [0.1, 0.9]\n",
    "sample, _ = rawDataRDD.randomSplit(weights, seed) \n",
    "sample.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/17 21:22:48 WARN BlockManager: Task 21 already completed, not releasing lock for rdd_13_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1000002 1000014 42',\n",
       " '1000002 1000088 157',\n",
       " '1000002 1000139 56',\n",
       " '1000002 1000140 95',\n",
       " '1000002 1000210 23']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the first 5 records from the sample. each row represents userID, artistID, count.\n",
    "sample.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:====================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2429895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print( sample.count() ) #why doesn't it take exactly 10%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Based on sampled data, build the matrix for model training\n",
    "def mapSingleObservation(x):\n",
    "    # Returns Rating object represented as (user, product, rating) tuple.\n",
    "    # [add line of code here to split each record into userID, artistID, count]\n",
    "    \n",
    "    splitPair = x.rsplit(' ')\n",
    "    userID, artistID, count = int(splitPair[0]), int(splitPair[1]), int(splitPair[2])\n",
    "    \n",
    "    # given possible aliasing, get finalArtistID\n",
    "    finalArtistID = artistAliasBroadcast.value.get(artistID)\n",
    "    if finalArtistID is None:\n",
    "        finalArtistID = artistID\n",
    "    return Rating(userID, finalArtistID, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[16] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = sample.map(lambda x: mapSingleObservation(x))\n",
    "trainData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Rating(user=1000002, product=1000014, rating=42.0),\n",
       " Rating(user=1000002, product=1000088, rating=157.0),\n",
       " Rating(user=1000002, product=1000139, rating=56.0),\n",
       " Rating(user=1000002, product=1000140, rating=95.0),\n",
       " Rating(user=1000002, product=1000210, rating=23.0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) (1 PT) Print the first 5 records from trainData\n",
    "trainData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Train the ALS implicit model (since the measurements are activity and not ratings)\n",
    "# using seed 314, rank 10, iterations 5, alpha 0.01\n",
    "model = ALS.trainImplicit(trainData, rank=10, iterations=5, alpha=0.01, seed = 314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "# fetch artists for a test user\n",
    "testUserID = 1000002\n",
    "\n",
    "# broadcast artistByID for speed\n",
    "artistByIDBroadcast = sc.broadcast( artistByID )\n",
    "\n",
    "# from trainData, collect the artists for the test user. Call the object artistsForUser.\n",
    "# hint: you will need to apply .value.get(x.product) to the broadcast artistByID, where x is the Rating RDD.\n",
    "# if you don't do this, you may see artistIDs. you want artist names.\n",
    "artistsForUser = (trainData\n",
    "                  .filter(lambda observation: observation.user == testUserID)\n",
    "                  .map(lambda observation: artistByIDBroadcast.value.get(observation.product))\n",
    "                  .collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Café Del Mar', 'Eric Clapton', 'Eurythmics']\n"
     ]
    }
   ],
   "source": [
    "# 4) (1 PT) Print the artist listens for testUserID = 1000002\n",
    "print([x for x in artistsForUser if x is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eric Clapton', '植松伸夫', 'Dark Tranquillity', 'Scorpions', 'Enigma', 'Eurythmics', 'Gary Jules', 'Elvis Costello', 'Saliva', 'Nena']\n"
     ]
    }
   ],
   "source": [
    "# 5) (2 PTS) Make 10 recommendations for testUserID = 1000002\n",
    "num_recomm = 600 # this filters down to 10 after filtering Nones\n",
    "recommendationsForUser = map(lambda observation: artistByID.get(observation.product), model.call(\"recommendProducts\", testUserID, num_recomm))\n",
    "\n",
    "print([x for x in recommendationsForUser if x is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Train a second ALS model with seed 314, rank 20, iterations 5, lambda 0.01.\n",
    "model = ALS.trainImplicit(trainData, rank=20, iterations=5, alpha=0.01, seed = 314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eric Clapton', 'Dark Tranquillity', 'Scorpions', '植松伸夫', 'Enigma', 'Eurythmics', 'Gary Jules', 'Hypocrisy', 'Elvis Costello', 'Nena']\n"
     ]
    }
   ],
   "source": [
    "# 6) (2 PTS) Using the rank 20 model, make 10 recommendations for the same test user\n",
    "recommendationsForUser_rank20 = map(lambda observation: artistByID.get(observation.product), model.call(\"recommendProducts\", testUserID, 520))\n",
    "print([x for x in recommendationsForUser_rank20 if x is not None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANSWER SECTION (COPY ALL ANSWERS HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 602:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/17 21:37:31 WARN BlockManager: Task 492 already completed, not releasing lock for rdd_1_0\n",
      "['1000002 1 55', '1000002 1000006 33', '1000002 1000007 8', '1000002 1000009 144', '1000002 1000010 314', '1000002 1000013 8', '1000002 1000014 42', '1000002 1000017 69', '1000002 1000024 329', '1000002 1000025 1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ANSWER 1 (1 PT)\n",
    "# Print the first 10 records from rawDataRDD\n",
    "print(rawDataRDD.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06Crazy Life',\n",
       " 'Pang Nakarin',\n",
       " 'Terfel, Bartoli- Mozart: Don',\n",
       " 'The Flaming Sidebur',\n",
       " 'Bodenstandig 3000',\n",
       " 'Jota Quest e Ivete Sangalo',\n",
       " 'Toto_XX (1977',\n",
       " 'U.S Bombs -',\n",
       " 'artist formaly know as Mat',\n",
       " 'Kassierer - Musik für beide Ohren']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER 2 (1 PT)\n",
    "# Apply parseArtistIdNamePair to rawArtistRDD and print the first 10 records, showing only artist names\n",
    "artistByID = dict(rawArtistRDD.flatMap(lambda x: parseArtistIdNamePair(x)).collect())\n",
    "artist_vals = artistByID.values()\n",
    "list(artist_vals)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rating(user=1000002, product=1000014, rating=42.0), Rating(user=1000002, product=1000088, rating=157.0), Rating(user=1000002, product=1000139, rating=56.0), Rating(user=1000002, product=1000140, rating=95.0), Rating(user=1000002, product=1000210, rating=23.0)]\n"
     ]
    }
   ],
   "source": [
    "# ANSWER 3 (1 PT)\n",
    "# Print the first 5 records from trainData\n",
    "print(trainData.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Café Del Mar', 'Eric Clapton', 'Eurythmics']\n"
     ]
    }
   ],
   "source": [
    "# ANSWER 4 (1 PT)\n",
    "# Print the artist listens for testUserID = 1000002\n",
    "print([x for x in artistsForUser if x is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 5 (2 PTS)\n",
    "# Make 10 recommendations for testUserID = 1000002\n",
    "num_recomm = 600 # this filters down to 10 after filtering Nones\n",
    "recommendationsForUser = map(lambda observation: artistByID.get(observation.product), model.call(\"recommendProducts\", testUserID, num_recomm))\n",
    "\n",
    "print([x for x in recommendationsForUser if x is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 6 (2 PTS)\n",
    "# Using the rank 20 model, make 10 recommendations for testUserID = 1000002\n",
    "recommendationsForUser_rank20 = map(lambda observation: artistByID.get(observation.product), model.call(\"recommendProducts\", testUserID, 520))\n",
    "print([x for x in recommendationsForUser_rank20 if x is not None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANSWER 7 (2 PTS)\n",
    "# How does the rank 10 model seem to perform versus the rank 20 model?\n",
    "# The contents of artistsForUser may help answer the question.\n",
    "Given that increasing rank increases the number of features/latent factors to use, you would expect the rank 20 model to perform better \n",
    "than the rank 10 model if more than 10 features prove important to recommending artists. The recommendation outputs are almost the same though.\n",
    "This is likely because the input data is the same and also extremely limited (only 3 artists)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS7200 Spark 3.3",
   "language": "python",
   "name": "ds5110_spark3.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
